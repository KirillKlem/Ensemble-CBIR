# -*- coding: utf-8 -*-
"""CBIR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jV-Wm6NKT3fDi70sk6YmkucXntwniVjl
"""

from transformers import ViTImageProcessor, ViTModel
from PIL import Image
import requests
import torch
import numpy as np
from torch import nn
import torch.nn.functional as F
from torchvision import transforms
import cv2

"""##CLIP"""

# Устанавливаем необходимые библиотеки
!pip install git+https://github.com/openai/CLIP.git
!pip install faiss-cpu

import clip
import torch
import faiss
from PIL import Image
import numpy as np

# Проверяем наличие GPU, иначе используем CPU
device = "cuda" if torch.cuda.is_available() else "cpu"
# Загружаем модель CLIP и процесс предобработки изображений
model, preprocess = clip.load("ViT-B/32", device=device)

# Функция для извлечения эмбеддингов изображений с помощью CLIP
def get_image_embedding(image_path):
    """
    Извлекает эмбеддинг изображения с помощью модели CLIP.

    Args:
        image_path (str): Путь к изображению.

    Returns:
        torch.Tensor: Нормализованный эмбеддинг изображения.

    Описание:
        Функция принимает путь к изображению, загружает и преобразует изображение,
        после чего вычисляет и нормализует эмбеддинг с помощью модели CLIP.
    """
    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)
    with torch.no_grad():
        embedding = model.encode_image(image)
    return embedding / embedding.norm(dim=-1, keepdim=True)


# Пример: создание списка путей к изображениям и извлечение эмбеддингов
import os

# Путь к папке с изображениями, организованными по классам
data_dir = '/content/drive/MyDrive/data'

# Сбор всех путей к изображениям в подкаталогах
image_paths = []
for root, dirs, files in os.walk(data_dir):
    for file in files:
        # Проверяем, что файл является изображением по расширению
        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):
            image_paths.append(os.path.join(root, file))

print(f"Найдено {len(image_paths)} изображений.")

from tqdm import tqdm
import numpy as np

# Параметры обработки в батчах
batch_size = 1000
database_embeddings = []

# Обработка изображений батчами для извлечения эмбеддингов
for i in range(0, len(image_paths), batch_size):
    # Получаем текущий батч путей к изображениям
    batch_paths = image_paths[i:min(i + batch_size, len(image_paths))]

    # Извлекаем эмбеддинги для изображений в текущем батче
    batch_embeddings = [get_image_embedding(img_path).cpu().numpy() for img_path in tqdm(batch_paths)]

    # Объединяем эмбеддинги текущего батча в единый массив
    batch_embeddings = np.vstack(batch_embeddings)
    database_embeddings.append(batch_embeddings)

    # Сохраняем батч эмбеддингов в отдельный файл
    np.save(f"/content/drive/MyDrive/embeddings_batch_{i // batch_size + 1}.npy", batch_embeddings)
    print(f"Батч {i // batch_size + 1} сохранён в embeddings_batch_{i // batch_size + 1}.npy")

import os
import numpy as np
import pandas as pd

# Путь к папке с эмбеддингами и с изображениями
embeddings_dir = '/content/drive/MyDrive/embeddings'
data_dir = '/content/drive/MyDrive/data'

# Загрузка путей к изображениям и меток
image_paths = []
labels = []
for root, dirs, files in os.walk(data_dir):
    for file in files:
        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):
            image_paths.append(os.path.join(root, file))
            labels.append(os.path.basename(root))

# Загрузка и объединение эмбеддингов всех батчей
embeddings = []
for i in range(1, 21):  # Предполагаем, что файлы эмбеддингов идут от 1 до 20
    embedding_file = os.path.join(embeddings_dir, f'embeddings_batch_{i}.npy')
    if os.path.exists(embedding_file):
        batch_embeddings = np.load(embedding_file)
        embeddings.extend(batch_embeddings)

# Проверка на соответствие числа эмбеддингов числу изображений
if len(embeddings) != len(image_paths):
    raise ValueError("Количество эмбеддингов не совпадает с количеством изображений!")

# Сохраняем пути к изображениям, метки и эмбеддинги в DataFrame
df = pd.DataFrame({
    'file_name': [os.path.basename(path) for path in image_paths],
    'label': labels,
    'embedding': embeddings
})

output_csv_path = 'embeddings.csv'
df.to_csv(output_csv_path, index=False)
print(f"Данные сохранены в {output_csv_path}")

# Объединяем все эмбеддинги в одном массиве для построения индекса
database_embeddings = np.vstack(database_embeddings)

# Инициализация индекса FAISS для быстрого поиска по косинусной схожести
index = faiss.IndexFlatIP(database_embeddings.shape[1])  # IndexFlatIP использует косинусное сходство
index.add(database_embeddings)

# Функция для поиска по изображению-запросу
def find_semantic_copies(query_image_path, top_k=10):
    """
    Находит топ-K похожих изображений для изображения-запроса.

    Args:
        query_image_path (str): Путь к изображению-запросу.
        top_k (int): Количество изображений, которые нужно вернуть (по умолчанию 10).

    Returns:
        list: Пути к похожим изображениям.

    Описание:
        Извлекает эмбеддинг изображения-запроса, находит его ближайших соседей
        в базе данных и возвращает пути к топ-K похожим изображениям.
    """
    # Извлекаем эмбеддинг изображения-запроса
    query_embedding = get_image_embedding(query_image_path).cpu().numpy()

    # Поиск ближайших соседей в индексе
    distances, indices = index.search(query_embedding, top_k)

    # Возвращаем пути к похожим изображениям
    similar_images = [image_paths[idx] for idx in indices[0]]
    return similar_images

# Подсчет точности рекомендованного набора изображений на основе совпадения классов
accuracies = []

for i, query_image in enumerate(image_paths):
    # Извлекаем класс искомого изображения
    query_class = extract_class(query_image)

    # Получаем рекомендованные изображения
    recommended_images = find_semantic_copies(query_image)

    # Извлекаем классы рекомендованных изображений
    recommended_classes = [extract_class(img) for img in recommended_images]

    # Рассчитываем точность для текущего изображения
    accuracy = sum(1 for cls in recommended_classes if cls == query_class) / len(recommended_classes)
    accuracies.append(accuracy)

    # Вывод для проверки
    print(f"Точность для изображения {i+1}: {accuracy:.2f}\n")

# Усредняем точность по всем изображениям
average_accuracy = sum(accuracies) / len(accuracies)
print(f"Средняя точность: {average_accuracy:.2f}")

# Функция для вычисления схожести между эмбеддингами с использованием косинусного сходства
def compute_difference(embedding1, embedding2, threshold=0.1):
    """
    Вычисляет косинусное сходство между двумя эмбеддингами.

    Args:
        embedding1 (torch.Tensor): Первый эмбеддинг.
        embedding2 (torch.Tensor): Второй эмбеддинг.
        threshold (float): Порог для фильтрации схожести (по умолчанию 0.1).

    Returns:
        torch.Tensor: Значение косинусного сходства.

    Описание:
        Вычисляет косинусное сходство между двумя эмбеддингами и возвращает его, если
        оно больше заданного порога.
    """
    embedding1 = torch.tensor(embedding1)
    embedding2 = torch.tensor(embedding2)
    diff = F.cosine_similarity(embedding1, embedding2)
    return diff

# Сравнение схожести между эмбеддингом запроса и эмбеддингами в базе данных
query_embedding = get_image_embedding(query_image).cpu().numpy()
distances, indices = index.search(query_embedding, 10)
diff_embedding = []
for idx in indices[0]:  # Для ближайших соседей
    diff_embedding += compute_difference(query_embedding, database_embeddings[idx])

# Создание и сохранение результатов сравнения в CSV-файл
data = {
    "image": [query_image],
    "recs": [",".join([img.split('/')[-1].replace(".jpg", "") for img in recommended_images])]
}
df = pd.DataFrame(data)
df.to_csv("submission.csv", index=False, sep=",")
print("Файл submission.csv успешно создан.")


"""# CNN"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model
import numpy as np
import pandas as pd
import os
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm
from google.colab import output

# Функция для создания модели для извлечения эмбеддингов на базе CNN
def create_feature_extractor(base_model_name='ResNet50V2'):
    """
    Создает модель для извлечения эмбеддингов на основе указанной архитектуры.

    Args:
        base_model_name (str): Название базовой модели (по умолчанию 'ResNet50V2').

    Returns:
        Model: Модель Keras для извлечения эмбеддингов.

    Описание:
        Поддерживаются модели ResNet50V2 и ConvNeXtTiny. Извлечение эмбеддингов производится
        с использованием глобального среднего пулинга, что упрощает дальнейшее сравнение изображений.
    """
    if base_model_name == 'ResNet50V2':
        base_model = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    elif base_model_name == 'ConvNeXtTiny':
        base_model = tf.keras.applications.ConvNeXtTiny(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    else:
        raise ValueError(f"Model {base_model_name} is not supported")

    # Извлечение признаков с помощью глобального среднего пулинга
    x = base_model.output
    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    model = Model(inputs=base_model.input, outputs=x)
    return model

# Функция для извлечения эмбеддингов и сохранения в DataFrame
def extract_embeddings(model, image_paths):
    """
    Извлекает эмбеддинги для заданного набора изображений и сохраняет их в DataFrame.

    Args:
        model (Model): Модель для извлечения эмбеддингов.
        image_paths (list): Список путей к изображениям.

    Returns:
        pd.DataFrame: DataFrame с эмбеддингами и именами файлов изображений.
    """
    feature_dim = model.output_shape[1]
    embeddings = np.zeros((len(image_paths), feature_dim), dtype='float32')
    file_names = []

    for i, img_path in tqdm(enumerate(image_paths)):
        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))
        img_array = tf.keras.preprocessing.image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)
        img_array = tf.keras.applications.resnet_v2.preprocess_input(img_array)
        features = model.predict(img_array, verbose=0)
        embeddings[i, :] = features.flatten()
        file_names.append(os.path.basename(img_path))

    # Создание DataFrame с именами файлов и эмбеддингами
    df = pd.DataFrame({'file_name': file_names, 'embedding': embeddings.tolist()})
    return df

# Сбор путей к изображениям для обработки
data_dir = '/content/drive/MyDrive/data'
image_paths = []
for root, dirs, files in os.walk(data_dir):
    for file in files:
        if file.lower().endswith(('.png', '.jpg', '.jpeg')):
            image_paths.append(os.path.join(root, file))

# Извлечение эмбеддингов с помощью модели
model = create_feature_extractor()
embeddings_df = extract_embeddings(model, image_paths)

# Сохранение эмбеддингов в CSV
output_csv_path = 'embeddings_with_labels.csv'
embeddings_df.to_csv(output_csv_path, index=False)
print(f"Данные сохранены в {output_csv_path}")

"""# Хэши"""

!pip install imagehash

import os
import imagehash
from PIL import Image
from tqdm import tqdm

# Функция для вычисления перцептивного хеша изображения
def calculate_phash(image_path):
    """
    Вычисляет перцептивный хеш для изображения с использованием pHash.

    Args:
        image_path (str): Путь к изображению.

    Returns:
        ImageHash: Хеш изображения.
    """
    image = Image.open(image_path)
    return imagehash.phash(image)

# Создание базы данных хешей для всех изображений
def create_hash_database(image_paths):
    """
    Создает базу данных хешей для заданного набора изображений.

    Args:
        image_paths (list): Список путей к изображениям.

    Returns:
        dict: Словарь с путями к изображениям и их хешами.
    """
    hash_database = {}
    for image_path in tqdm(image_paths, desc="Создание базы данных хешей"):
        try:
            hash_value = calculate_phash(image_path)
            hash_database[image_path] = hash_value
        except Exception as e:
            print(f"Ошибка при обработке {image_path}: {e}")
    return hash_database

# Функция для поиска похожих изображений на основе перцептивных хешей
def find_similar_images(query_image_path, hash_database, threshold=10):
    """
    Находит похожие изображения на основе расстояния Хэмминга между хешами.

    Args:
        query_image_path (str): Путь к изображению-запросу.
        hash_database (dict): База данных хешей изображений.
        threshold (int): Порог для расстояния Хэмминга (по умолчанию 10).

    Returns:
        list: Список похожих изображений.
    """
    query_hash = calculate_phash(query_image_path)
    similar_images = []

    for image_path, hash_value in hash_database.items():
        # Вычисляем расстояние Хэмминга между хешами
        distance = query_hash - hash_value
        if distance <= threshold:
            similar_images.append((image_path, distance))

    # Сортируем результаты по расстоянию
    similar_images.sort(key=lambda x: x[1])
    return [img[0] for img in similar_images]
